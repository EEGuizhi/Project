{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 實驗與測試區"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import可能會用到的 套件/模組  (需執行)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from munch import Munch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python index test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### python index test\n",
    "heatmap = np.array([[0.2, 0.5, 0.8], [0.9, 0.3, 0.6], [0.1, 0.7, 0.4]])\n",
    "threshold = 0.5\n",
    "print(\"heatmap:\", heatmap)  # output: heatmap: [[0.2 0.5 0.8]\n",
    "                            #                   [0.9 0.3 0.6]\n",
    "                            #                   [0.1 0.7 0.4]]\n",
    "heatmap[heatmap < threshold] = 0\n",
    "print(\"heatmap:\", heatmap)  # output: heatmap: [[0.2 0.5 0.8]\n",
    "                            #                   [0.9 0.  0.6]\n",
    "                            #                   [0.  0.7 0. ]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BCELoss test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BCELoss test\n",
    "m = nn.Sigmoid()\n",
    "# bce_loss = nn.BCELoss(reduction='sum')  # 沒有平均\n",
    "bce_loss = nn.BCELoss()  # 有平均\n",
    "output = torch.tensor([-1, -2, -3, 1, 2, 3], dtype=torch.float32)\n",
    "output = m(output)  # 先處理一次 (將數值轉到0~1之間)\n",
    "target = torch.tensor([0, 1, 0, 0, 0, 1], dtype=torch.float32)\n",
    "loss = bce_loss(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型並聯 (提供by ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 模型並聯\n",
    "class ParallelConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_convs):\n",
    "        super(ParallelConv, self).__init__()\n",
    "        self.num_convs = num_convs\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1) for i in range(num_convs)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for i in range(self.num_convs):\n",
    "            outputs.append(self.convs[i](x))\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary / Munch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dictionary test\n",
    "cfg = []\n",
    "\n",
    "# test 1\n",
    "cfg.append(\n",
    "    dict(num_modules=1, num_branches=1, block='BOTTLENECK', num_blocks=(4), num_channels=(64, ))\n",
    ")\n",
    "\n",
    "# test 2\n",
    "cfg.append(\n",
    "    dict(\n",
    "        MODEL = dict(\n",
    "            NAME = \"cls_hrnet\",\n",
    "            IMAGE_SIZE = (224, 224)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# test 3\n",
    "cfg.append(\n",
    "    Munch()\n",
    ")\n",
    "cfg[-1].MODEL = Munch()\n",
    "cfg[-1].MODEL.NAME = \"cls_hrnet\"\n",
    "\n",
    "# test 4\n",
    "cfg.append(\n",
    "    {\n",
    "        \"MODEL\" : {\n",
    "            \"NAME\" : \"cls_hrnet\",\n",
    "            \"IMAGE_SIZE\" : (224, 224)\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Log Output\n",
    "for i in range(len(cfg)):\n",
    "    print(\"\\n===\")\n",
    "    print(\">> cfg[{}] : {}\".format(i, cfg[i]))\n",
    "    try:\n",
    "        print(\">> cfg[{}]['MODEL'] : {}\".format(i, cfg[i]['MODEL']))\n",
    "    except:\n",
    "        print(\">> cfg[{}]['MODEL'] : error\".format(i))\n",
    "    try:\n",
    "        print(\">> cfg[{}].MODEL : {}\".format(i, cfg[i].MODEL))\n",
    "    except:\n",
    "        print(\">> cfg[{}].MODEL : error\".format(i))\n",
    "    try:\n",
    "        print(\">> cfg[{}].MODEL.NAME : {}\".format(i, cfg[i].MODEL.NAME))\n",
    "    except:\n",
    "        print(\">> cfg[{}].MODEL.NAME : error\".format(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX test (簡單模型視覺化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### onnx test\n",
    "BN_MOMENTUM = 0.1\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, momentum=BN_MOMENTUM)\n",
    "        self.conv3 = nn.Conv2d(planes, planes*self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes*self.expansion, momentum=BN_MOMENTUM)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)  # layer 1\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)  # layer 2\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)  # layer 3\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def Convert_ONNX(model):\n",
    "    # set the model to inference mode\n",
    "    model.eval() \n",
    "\n",
    "    # Let's create a dummy input tensor\n",
    "    dummy_input = torch.randn(1, 4, 5, 5)  \n",
    "\n",
    "    # Export the model\n",
    "    torch.onnx.export(model,  # model being run \n",
    "         dummy_input,  # model input (or a tuple for multiple inputs)\n",
    "         \"Bottleneck.onnx\",  # where to save the model\n",
    "         export_params=True,  # store the trained parameter weights inside the model file\n",
    "         opset_version=10,  # the ONNX version to export the model to\n",
    "         do_constant_folding=True,  # whether to execute constant folding for optimization \n",
    "         input_names = ['modelInput'],  # the model's input names\n",
    "         output_names = ['modelOutput'],  # the model's output names\n",
    "         dynamic_axes={'modelInput' : {0 : 'batch_size'}, 'modelOutput' : {0 : 'batch_size'}}  # variable length axes\n",
    "    )\n",
    "    print(\"\\n>> Model has been converted to ONNX\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = Bottleneck(4, 1)\n",
    "    Convert_ONNX(model)\n",
    "    \n",
    "    # from torch.utils.tensorboard import SummaryWriter\n",
    "    # tb = SummaryWriter()\n",
    "    # dummy_input = torch.randn(1, 4, 5, 5)\n",
    "    # tb.add_graph(model, dummy_input)\n",
    "    # tb.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.zeros_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "heatmap = torch.randn(2, 5, 5)  # 隨便假設一個tensor\n",
    "hint_heatmap = torch.zeros_like(heatmap)  # torch.zeros_like()裡面不只可以放\"大小\" 也可以放一個tesor然後自動取同樣大小\n",
    "print(\">> heatmap:\\n{}\".format(heatmap))\n",
    "print(\">> hint_heatmap:\\n{}\".format(hint_heatmap))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### def in def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### def in def\n",
    "def f1():\n",
    "    print(\">> i'm f1\")\n",
    "    \n",
    "    def f2():\n",
    "        print(\">> i'm f2\")\n",
    "    \n",
    "    return f2  # return a func\n",
    "    # return f2()  # error\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    func = f1()\n",
    "    print(\"===\")\n",
    "    func()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x.max(-1)[0].max(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> output 1:\n",
      " tensor([[[[-1.0871, -1.1618,  0.3339, -0.5203],\n",
      "          [-1.0547,  1.0364, -0.5271, -0.9846],\n",
      "          [ 1.6209,  0.9571, -0.1905,  1.4312],\n",
      "          [ 0.1845,  1.5194,  0.8394,  0.6333]],\n",
      "\n",
      "         [[ 0.1649, -0.1122, -0.8891, -1.6489],\n",
      "          [-0.9267,  0.4304, -1.4816,  0.9661],\n",
      "          [ 0.3071, -0.7597,  1.2191, -1.0868],\n",
      "          [ 1.0381,  0.7510,  1.3260, -0.7669]],\n",
      "\n",
      "         [[ 0.2250, -1.1625, -0.3998, -0.5687],\n",
      "          [-1.1811, -0.6107,  1.0771, -1.5059],\n",
      "          [ 0.5723, -0.3194,  0.4381,  0.1106],\n",
      "          [ 1.4437,  0.8442,  0.5846,  0.6537]]],\n",
      "\n",
      "\n",
      "        [[[-0.1766,  0.6198,  0.3551,  0.1644],\n",
      "          [-1.5710,  0.4620,  1.2219,  0.1832],\n",
      "          [-0.5226, -1.5287,  0.0435,  0.7526],\n",
      "          [-1.9009, -0.2130,  1.2209, -0.0549]],\n",
      "\n",
      "         [[ 0.0584, -0.2719,  1.5653,  2.2117],\n",
      "          [ 1.7956,  2.1105, -0.7260, -2.0059],\n",
      "          [ 0.2171,  1.2955, -0.7319, -0.7861],\n",
      "          [ 0.8259, -0.3915, -1.9438,  0.2664]],\n",
      "\n",
      "         [[-0.1306,  0.3253, -0.1229,  1.7329],\n",
      "          [-1.0197, -0.9372,  0.2817,  0.5549],\n",
      "          [-0.1211, -0.3472, -0.3258,  0.4783],\n",
      "          [ 0.8847,  0.4665, -0.9656, -0.9818]]]])\n",
      ">> output 2:\n",
      " tensor([[1.6209, 1.3260, 1.4437],\n",
      "        [1.2219, 2.2117, 1.7329]])\n",
      ">> output 3:\n",
      " tensor([[[[1.6209]],\n",
      "\n",
      "         [[1.3260]],\n",
      "\n",
      "         [[1.4437]]],\n",
      "\n",
      "\n",
      "        [[[1.2219]],\n",
      "\n",
      "         [[2.2117]],\n",
      "\n",
      "         [[1.7329]]]])\n",
      ">> multi:\n",
      " tensor([[[[-1.7621, -1.8832,  0.5413, -0.8434],\n",
      "          [-1.7096,  1.6800, -0.8544, -1.5959],\n",
      "          [ 2.6275,  1.5515, -0.3088,  2.3199],\n",
      "          [ 0.2990,  2.4629,  1.3607,  1.0266]],\n",
      "\n",
      "         [[ 0.2186, -0.1488, -1.1789, -2.1863],\n",
      "          [-1.2287,  0.5706, -1.9646,  1.2810],\n",
      "          [ 0.4072, -1.0074,  1.6165, -1.4410],\n",
      "          [ 1.3764,  0.9958,  1.7582, -1.0168]],\n",
      "\n",
      "         [[ 0.3248, -1.6784, -0.5772, -0.8210],\n",
      "          [-1.7052, -0.8816,  1.5550, -2.1741],\n",
      "          [ 0.8262, -0.4611,  0.6325,  0.1596],\n",
      "          [ 2.0843,  1.2187,  0.8439,  0.9438]]],\n",
      "\n",
      "\n",
      "        [[[-1.3283, -1.4197,  0.4081, -0.6358],\n",
      "          [-1.2888,  1.2664, -0.6441, -1.2031],\n",
      "          [ 1.9807,  1.1695, -0.2328,  1.7489],\n",
      "          [ 0.2254,  1.8566,  1.0257,  0.7739]],\n",
      "\n",
      "         [[ 0.3647, -0.2482, -1.9664, -3.6469],\n",
      "          [-2.0496,  0.9518, -3.2770,  2.1368],\n",
      "          [ 0.6792, -1.6804,  2.6963, -2.4036],\n",
      "          [ 2.2959,  1.6610,  2.9327, -1.6961]],\n",
      "\n",
      "         [[ 0.3899, -2.0146, -0.6928, -0.9855],\n",
      "          [-2.0468, -1.0582,  1.8665, -2.6096],\n",
      "          [ 0.9917, -0.5535,  0.7592,  0.1916],\n",
      "          [ 2.5018,  1.4629,  1.0130,  1.1328]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假設一個大小為(2, 3, 4, 4)的Tensor\n",
    "x = torch.randn(2, 3, 4, 4)\n",
    "print(\">> output 1:\\n\",x)\n",
    "\n",
    "# 取得第二維度與第三維度上的最大值\n",
    "y = x.max(-1)[0].max(-1)[0]\n",
    "print(\">> output 2:\\n\",y)\n",
    "\n",
    "# 將x的最後兩個維度添加維度大小為1的維度\n",
    "y = y[:, :, None, None]\n",
    "print(\">> output 3:\\n\",y)\n",
    "\n",
    "print(\">> multi:\\n\", x[0]*y)\n",
    "\n",
    "# print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = torch.randn(2, 3, 3)\n",
    "\n",
    "init_value = 0.05\n",
    "lr_mult = 1\n",
    "scale = nn.Parameter(\n",
    "    torch.full((1,), init_value / lr_mult, dtype=torch.float32)\n",
    ")\n",
    "\n",
    "print(\">> scale: {}\".format(scale))\n",
    "print(\">> scale.shape: {}\".format(scale.shape))\n",
    "print(\">> map:\\n\", map)\n",
    "print(\">> map.shape: {}\".format(map.shape))\n",
    "\n",
    "map = map * scale\n",
    "print(\">> map after scaled:\\n\", map)\n",
    "print(\">> map after scaled shape: {}\".format(map.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = torch.randn(2, 3, 3)\n",
    "test = torch.tensor([[[1, ]]])\n",
    "\n",
    "print(\">> map:\\n\", map)\n",
    "print(\">> map:\\n\", map * test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.cat(dim=?) test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.6253,  0.5435, -0.3234],\n",
      "          [-1.4810, -1.0507, -1.7989],\n",
      "          [ 0.7850,  1.1157,  2.7274]],\n",
      "\n",
      "         [[-2.6347,  0.0996,  1.2286],\n",
      "          [-0.8987, -0.1481,  0.2430],\n",
      "          [-0.3481,  0.2867,  0.4681]]]])\n",
      "tensor([[[[ 0.6253,  0.5435, -0.3234],\n",
      "          [-1.4810, -1.0507, -1.7989],\n",
      "          [ 0.7850,  1.1157,  2.7274]],\n",
      "\n",
      "         [[-2.6347,  0.0996,  1.2286],\n",
      "          [-0.8987, -0.1481,  0.2430],\n",
      "          [-0.3481,  0.2867,  0.4681]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000]]]])\n",
      ">> f1 shape: torch.Size([1, 2, 3, 3])\n",
      ">> f_cat shape: torch.Size([1, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "f1 = torch.randn(1, 2, 3, 3)\n",
    "f2 = torch.ones(1, 2, 3, 3)\n",
    "print(f1)\n",
    "f_cat = torch.cat((f1, f2), dim=1)\n",
    "print(f_cat)\n",
    "print(\">> f1 shape: {}\".format(f1.shape))\n",
    "print(\">> f_cat shape: {}\".format(f_cat.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
